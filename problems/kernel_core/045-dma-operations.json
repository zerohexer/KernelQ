{
  "id": 45,
  "title": "DMA Operations and Coherent Memory",
  "difficulty": 10,
  "xp": 100,
  "phase": "kernel_core",
  "description": "Implement DMA (Direct Memory Access) operations with coherent memory allocation and proper cache management. This teaches advanced memory management and DMA techniques critical for high-performance device drivers.",
  "concepts": ["DMA", "coherent_memory", "cache_coherency", "bus_addresses", "dma_mapping", "streaming_dma"],
  "skills": ["dma_programming", "memory_coherency", "cache_management", "bus_architecture", "high_performance_io"],
  "starter": "#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n#include <linux/device.h>\n#include <linux/cdev.h>\n#include <linux/uaccess.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/dma-mapping.h>\n#include <linux/dmapool.h>\n#include <linux/platform_device.h>\n#include <linux/completion.h>\n#include <linux/timer.h>\n#include <linux/jiffies.h>\n\n#define DEVICE_NAME \"dmadev\"\n#define CLASS_NAME \"dmaclass\"\n#define DMA_BUFFER_SIZE 4096\n#define MAX_DMA_TRANSFERS 8\n#define DMA_POOL_SIZE 1024\n#define DMA_POOL_ALIGN 64\n\n// TODO: DMA transfer descriptor\nstruct dma_transfer {\n    struct list_head list;\n    void *cpu_addr;          // CPU virtual address\n    dma_addr_t dma_addr;     // Bus address for DMA\n    size_t size;\n    enum dma_data_direction direction;\n    struct completion completion;\n    int transfer_id;\n    unsigned long start_jiffies;\n    bool completed;\n};\n\n// TODO: DMA statistics\nstruct dma_stats {\n    unsigned long transfers_started;\n    unsigned long transfers_completed;\n    unsigned long transfers_failed;\n    unsigned long coherent_allocs;\n    unsigned long streaming_maps;\n    unsigned long cache_syncs;\n    unsigned long total_bytes_transferred;\n};\n\n// TODO: Device structure\nstruct dma_device {\n    struct cdev cdev;\n    struct device *device;\n    struct class *class;\n    dev_t dev_num;\n    \n    // Platform device for DMA operations\n    struct platform_device *pdev;\n    \n    // DMA management\n    void *coherent_buffer;\n    dma_addr_t coherent_dma_addr;\n    size_t coherent_size;\n    \n    struct dma_pool *dma_pool;\n    \n    // Transfer management\n    struct list_head active_transfers;\n    struct list_head completed_transfers;\n    struct mutex transfer_mutex;\n    atomic_t next_transfer_id;\n    \n    // Simulation\n    struct timer_list dma_completion_timer;\n    \n    // Statistics\n    struct dma_stats stats;\n    \n    // User buffer for data\n    char *user_buffer;\n    size_t buffer_used;\n};\n\nstatic struct dma_device dma_dev;\n\n// TODO: DMA completion simulation timer\nstatic void dma_completion_timer_callback(struct timer_list *timer)\n{\n    struct dma_device *dev = container_of(timer, struct dma_device, dma_completion_timer);\n    struct dma_transfer *transfer, *tmp;\n    bool found_active = false;\n    \n    mutex_lock(&dev->transfer_mutex);\n    \n    // Simulate completion of oldest active transfer\n    list_for_each_entry_safe(transfer, tmp, &dev->active_transfers, list) {\n        if (jiffies - transfer->start_jiffies >= msecs_to_jiffies(2000)) {\n            // Mark transfer as completed\n            transfer->completed = true;\n            complete(&transfer->completion);\n            \n            // Move to completed list\n            list_del(&transfer->list);\n            list_add_tail(&transfer->list, &dev->completed_transfers);\n            \n            dev->stats.transfers_completed++;\n            dev->stats.total_bytes_transferred += transfer->size;\n            \n            printk(KERN_INFO \"DMA transfer %d completed (size: %zu, direction: %d)\\n\",\n                   transfer->transfer_id, transfer->size, transfer->direction);\n            \n            break;\n        }\n        found_active = true;\n    }\n    \n    mutex_unlock(&dev->transfer_mutex);\n    \n    // Restart timer if there are still active transfers\n    if (found_active) {\n        mod_timer(&dev->dma_completion_timer, jiffies + msecs_to_jiffies(500));\n    }\n}\n\n// TODO: Allocate coherent DMA memory\nstatic int allocate_coherent_memory(struct dma_device *dev)\n{\n    dev->coherent_size = DMA_BUFFER_SIZE;\n    \n    // Allocate coherent memory (uncached, suitable for DMA)\n    dev->coherent_buffer = dma_alloc_coherent(&dev->pdev->dev,\n                                             dev->coherent_size,\n                                             &dev->coherent_dma_addr,\n                                             GFP_KERNEL);\n    \n    if (!dev->coherent_buffer) {\n        printk(KERN_ERR \"Failed to allocate coherent DMA memory\\n\");\n        return -ENOMEM;\n    }\n    \n    dev->stats.coherent_allocs++;\n    \n    printk(KERN_INFO \"Allocated coherent memory: CPU addr=%p, DMA addr=0x%llx, size=%zu\\n\",\n           dev->coherent_buffer, (unsigned long long)dev->coherent_dma_addr, dev->coherent_size);\n    \n    // Initialize buffer with pattern\n    memset(dev->coherent_buffer, 0xAA, dev->coherent_size);\n    \n    return 0;\n}\n\n// TODO: Free coherent DMA memory\nstatic void free_coherent_memory(struct dma_device *dev)\n{\n    if (dev->coherent_buffer) {\n        dma_free_coherent(&dev->pdev->dev,\n                         dev->coherent_size,\n                         dev->coherent_buffer,\n                         dev->coherent_dma_addr);\n        dev->coherent_buffer = NULL;\n    }\n}\n\n// TODO: Start a DMA transfer\nstatic struct dma_transfer *start_dma_transfer(struct dma_device *dev,\n                                              void *data, size_t size,\n                                              enum dma_data_direction direction)\n{\n    struct dma_transfer *transfer;\n    void *pool_addr;\n    dma_addr_t pool_dma_addr;\n    \n    if (size > DMA_POOL_SIZE) {\n        printk(KERN_ERR \"Transfer size %zu exceeds pool size %d\\n\", size, DMA_POOL_SIZE);\n        return ERR_PTR(-EINVAL);\n    }\n    \n    // Allocate transfer descriptor\n    transfer = kzalloc(sizeof(*transfer), GFP_KERNEL);\n    if (!transfer) {\n        return ERR_PTR(-ENOMEM);\n    }\n    \n    // Allocate DMA pool memory\n    pool_addr = dma_pool_alloc(dev->dma_pool, GFP_KERNEL, &pool_dma_addr);\n    if (!pool_addr) {\n        kfree(transfer);\n        return ERR_PTR(-ENOMEM);\n    }\n    \n    // Initialize transfer\n    transfer->cpu_addr = pool_addr;\n    transfer->dma_addr = pool_dma_addr;\n    transfer->size = size;\n    transfer->direction = direction;\n    transfer->transfer_id = atomic_inc_return(&dev->next_transfer_id);\n    transfer->start_jiffies = jiffies;\n    transfer->completed = false;\n    init_completion(&transfer->completion);\n    \n    // Copy data for TO_DEVICE transfers\n    if (direction == DMA_TO_DEVICE && data) {\n        memcpy(pool_addr, data, size);\n    }\n    \n    // Map for DMA (streaming mapping)\n    dma_sync_single_for_device(&dev->pdev->dev,\n                              pool_dma_addr,\n                              size,\n                              direction);\n    \n    dev->stats.streaming_maps++;\n    dev->stats.cache_syncs++;\n    \n    mutex_lock(&dev->transfer_mutex);\n    list_add_tail(&transfer->list, &dev->active_transfers);\n    dev->stats.transfers_started++;\n    mutex_unlock(&dev->transfer_mutex);\n    \n    // Start completion timer if not already running\n    if (!timer_pending(&dev->dma_completion_timer)) {\n        mod_timer(&dev->dma_completion_timer, jiffies + msecs_to_jiffies(500));\n    }\n    \n    printk(KERN_INFO \"Started DMA transfer %d: addr=0x%llx, size=%zu, direction=%d\\n\",\n           transfer->transfer_id, (unsigned long long)pool_dma_addr, size, direction);\n    \n    return transfer;\n}\n\n// TODO: Wait for DMA transfer completion\nstatic int wait_for_transfer(struct dma_device *dev, struct dma_transfer *transfer,\n                           void *user_data, size_t user_size)\n{\n    int ret;\n    \n    // Wait for completion (with timeout)\n    ret = wait_for_completion_timeout(&transfer->completion, msecs_to_jiffies(5000));\n    if (ret == 0) {\n        printk(KERN_ERR \"DMA transfer %d timed out\\n\", transfer->transfer_id);\n        dev->stats.transfers_failed++;\n        return -ETIMEDOUT;\n    }\n    \n    // Sync cache after DMA completion\n    dma_sync_single_for_cpu(&dev->pdev->dev,\n                           transfer->dma_addr,\n                           transfer->size,\n                           transfer->direction);\n    \n    dev->stats.cache_syncs++;\n    \n    // Copy data for FROM_DEVICE transfers\n    if (transfer->direction == DMA_FROM_DEVICE && user_data) {\n        size_t copy_size = min(user_size, transfer->size);\n        memcpy(user_data, transfer->cpu_addr, copy_size);\n    }\n    \n    printk(KERN_INFO \"DMA transfer %d completed successfully\\n\", transfer->transfer_id);\n    return 0;\n}\n\n// TODO: Cleanup completed transfer\nstatic void cleanup_transfer(struct dma_device *dev, struct dma_transfer *transfer)\n{\n    mutex_lock(&dev->transfer_mutex);\n    list_del(&transfer->list);\n    mutex_unlock(&dev->transfer_mutex);\n    \n    // Free DMA pool memory\n    dma_pool_free(dev->dma_pool, transfer->cpu_addr, transfer->dma_addr);\n    kfree(transfer);\n}\n\nstatic int device_open(struct inode *inode, struct file *file)\n{\n    file->private_data = &dma_dev;\n    printk(KERN_INFO \"DMA device opened\\n\");\n    return 0;\n}\n\nstatic int device_release(struct inode *inode, struct file *file)\n{\n    printk(KERN_INFO \"DMA device closed\\n\");\n    return 0;\n}\n\n// TODO: Read function using DMA\nstatic ssize_t device_read(struct file *file, char __user *user_buffer,\n                          size_t count, loff_t *offset)\n{\n    struct dma_device *dev = file->private_data;\n    struct dma_transfer *transfer;\n    char *temp_buffer;\n    ssize_t bytes_read = 0;\n    int ret;\n    \n    if (count == 0) {\n        return 0;\n    }\n    \n    count = min(count, (size_t)DMA_POOL_SIZE);\n    \n    temp_buffer = kzalloc(count, GFP_KERNEL);\n    if (!temp_buffer) {\n        return -ENOMEM;\n    }\n    \n    // Start DMA transfer from device (simulated read from coherent buffer)\n    memcpy(temp_buffer, dev->coherent_buffer, min(count, dev->coherent_size));\n    \n    transfer = start_dma_transfer(dev, temp_buffer, count, DMA_FROM_DEVICE);\n    if (IS_ERR(transfer)) {\n        kfree(temp_buffer);\n        return PTR_ERR(transfer);\n    }\n    \n    // Wait for transfer completion\n    ret = wait_for_transfer(dev, transfer, temp_buffer, count);\n    if (ret) {\n        cleanup_transfer(dev, transfer);\n        kfree(temp_buffer);\n        return ret;\n    }\n    \n    // Copy to user space\n    if (copy_to_user(user_buffer, temp_buffer, count)) {\n        cleanup_transfer(dev, transfer);\n        kfree(temp_buffer);\n        return -EFAULT;\n    }\n    \n    bytes_read = count;\n    cleanup_transfer(dev, transfer);\n    kfree(temp_buffer);\n    \n    printk(KERN_INFO \"DMA read completed: %zu bytes\\n\", bytes_read);\n    return bytes_read;\n}\n\n// TODO: Write function using DMA\nstatic ssize_t device_write(struct file *file, const char __user *user_buffer,\n                           size_t count, loff_t *offset)\n{\n    struct dma_device *dev = file->private_data;\n    struct dma_transfer *transfer;\n    char *temp_buffer;\n    ssize_t bytes_written = 0;\n    int ret;\n    \n    if (count == 0) {\n        return 0;\n    }\n    \n    count = min(count, (size_t)DMA_POOL_SIZE);\n    \n    temp_buffer = kzalloc(count, GFP_KERNEL);\n    if (!temp_buffer) {\n        return -ENOMEM;\n    }\n    \n    // Copy from user space\n    if (copy_from_user(temp_buffer, user_buffer, count)) {\n        kfree(temp_buffer);\n        return -EFAULT;\n    }\n    \n    // Start DMA transfer to device\n    transfer = start_dma_transfer(dev, temp_buffer, count, DMA_TO_DEVICE);\n    if (IS_ERR(transfer)) {\n        kfree(temp_buffer);\n        return PTR_ERR(transfer);\n    }\n    \n    // Wait for transfer completion\n    ret = wait_for_transfer(dev, transfer, NULL, 0);\n    if (ret) {\n        cleanup_transfer(dev, transfer);\n        kfree(temp_buffer);\n        return ret;\n    }\n    \n    // Simulate writing to coherent buffer\n    memcpy(dev->coherent_buffer, temp_buffer, min(count, dev->coherent_size));\n    \n    bytes_written = count;\n    cleanup_transfer(dev, transfer);\n    kfree(temp_buffer);\n    \n    printk(KERN_INFO \"DMA write completed: %zu bytes\\n\", bytes_written);\n    return bytes_written;\n}\n\nstatic const struct file_operations dma_dev_fops = {\n    .owner = THIS_MODULE,\n    .open = device_open,\n    .release = device_release,\n    .read = device_read,\n    .write = device_write,\n};\n\nstatic int __init dma_dev_init(void)\n{\n    int ret;\n    \n    printk(KERN_INFO \"DMA device driver initializing...\\n\");\n    \n    // TODO: Initialize device structure\n    memset(&dma_dev, 0, sizeof(dma_dev));\n    mutex_init(&dma_dev.transfer_mutex);\n    INIT_LIST_HEAD(&dma_dev.active_transfers);\n    INIT_LIST_HEAD(&dma_dev.completed_transfers);\n    atomic_set(&dma_dev.next_transfer_id, 0);\n    \n    // TODO: Create platform device for DMA operations\n    dma_dev.pdev = platform_device_register_simple(\"dma-demo\", -1, NULL, 0);\n    if (IS_ERR(dma_dev.pdev)) {\n        return PTR_ERR(dma_dev.pdev);\n    }\n    \n    // TODO: Set DMA mask\n    ret = dma_set_mask_and_coherent(&dma_dev.pdev->dev, DMA_BIT_MASK(32));\n    if (ret) {\n        platform_device_unregister(dma_dev.pdev);\n        return ret;\n    }\n    \n    // TODO: Allocate coherent memory\n    ret = allocate_coherent_memory(&dma_dev);\n    if (ret) {\n        platform_device_unregister(dma_dev.pdev);\n        return ret;\n    }\n    \n    // TODO: Create DMA pool\n    dma_dev.dma_pool = dma_pool_create(\"demo_pool\",\n                                      &dma_dev.pdev->dev,\n                                      DMA_POOL_SIZE,\n                                      DMA_POOL_ALIGN,\n                                      0);\n    if (!dma_dev.dma_pool) {\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return -ENOMEM;\n    }\n    \n    // TODO: Initialize timer\n    timer_setup(&dma_dev.dma_completion_timer, dma_completion_timer_callback, 0);\n    \n    // TODO: Allocate user buffer\n    dma_dev.user_buffer = kzalloc(DMA_BUFFER_SIZE, GFP_KERNEL);\n    if (!dma_dev.user_buffer) {\n        dma_pool_destroy(dma_dev.dma_pool);\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return -ENOMEM;\n    }\n    \n    // TODO: Register character device\n    ret = alloc_chrdev_region(&dma_dev.dev_num, 0, 1, DEVICE_NAME);\n    if (ret < 0) {\n        kfree(dma_dev.user_buffer);\n        dma_pool_destroy(dma_dev.dma_pool);\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return ret;\n    }\n    \n    cdev_init(&dma_dev.cdev, &dma_dev_fops);\n    dma_dev.cdev.owner = THIS_MODULE;\n    \n    ret = cdev_add(&dma_dev.cdev, dma_dev.dev_num, 1);\n    if (ret < 0) {\n        unregister_chrdev_region(dma_dev.dev_num, 1);\n        kfree(dma_dev.user_buffer);\n        dma_pool_destroy(dma_dev.dma_pool);\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return ret;\n    }\n    \n    // TODO: Create device class and device\n    dma_dev.class = class_create(THIS_MODULE, CLASS_NAME);\n    if (IS_ERR(dma_dev.class)) {\n        cdev_del(&dma_dev.cdev);\n        unregister_chrdev_region(dma_dev.dev_num, 1);\n        kfree(dma_dev.user_buffer);\n        dma_pool_destroy(dma_dev.dma_pool);\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return PTR_ERR(dma_dev.class);\n    }\n    \n    dma_dev.device = device_create(dma_dev.class, NULL, dma_dev.dev_num,\n                                  NULL, DEVICE_NAME);\n    if (IS_ERR(dma_dev.device)) {\n        class_destroy(dma_dev.class);\n        cdev_del(&dma_dev.cdev);\n        unregister_chrdev_region(dma_dev.dev_num, 1);\n        kfree(dma_dev.user_buffer);\n        dma_pool_destroy(dma_dev.dma_pool);\n        free_coherent_memory(&dma_dev);\n        platform_device_unregister(dma_dev.pdev);\n        return PTR_ERR(dma_dev.device);\n    }\n    \n    printk(KERN_INFO \"DMA device driver loaded successfully\\n\");\n    printk(KERN_INFO \"Device: /dev/%s with DMA support\\n\", DEVICE_NAME);\n    printk(KERN_INFO \"Coherent buffer: %zu bytes, DMA pool: %d bytes\\n\",\n           dma_dev.coherent_size, DMA_POOL_SIZE);\n    \n    return 0;\n}\n\nstatic void __exit dma_dev_exit(void)\n{\n    struct dma_transfer *transfer, *tmp;\n    \n    printk(KERN_INFO \"DMA device driver unloading...\\n\");\n    \n    // TODO: Stop timer and clean up transfers\n    del_timer_sync(&dma_dev.dma_completion_timer);\n    \n    // TODO: Clean up any remaining transfers\n    mutex_lock(&dma_dev.transfer_mutex);\n    list_for_each_entry_safe(transfer, tmp, &dma_dev.active_transfers, list) {\n        list_del(&transfer->list);\n        dma_pool_free(dma_dev.dma_pool, transfer->cpu_addr, transfer->dma_addr);\n        kfree(transfer);\n    }\n    list_for_each_entry_safe(transfer, tmp, &dma_dev.completed_transfers, list) {\n        list_del(&transfer->list);\n        dma_pool_free(dma_dev.dma_pool, transfer->cpu_addr, transfer->dma_addr);\n        kfree(transfer);\n    }\n    mutex_unlock(&dma_dev.transfer_mutex);\n    \n    // TODO: Clean up device\n    device_destroy(dma_dev.class, dma_dev.dev_num);\n    class_destroy(dma_dev.class);\n    cdev_del(&dma_dev.cdev);\n    unregister_chrdev_region(dma_dev.dev_num, 1);\n    \n    // TODO: Clean up DMA resources\n    kfree(dma_dev.user_buffer);\n    dma_pool_destroy(dma_dev.dma_pool);\n    free_coherent_memory(&dma_dev);\n    platform_device_unregister(dma_dev.pdev);\n    \n    printk(KERN_INFO \"DMA device driver unloaded\\n\");\n    printk(KERN_INFO \"Final DMA stats - Started: %lu, Completed: %lu, Failed: %lu, Bytes: %lu\\n\",\n           dma_dev.stats.transfers_started, dma_dev.stats.transfers_completed,\n           dma_dev.stats.transfers_failed, dma_dev.stats.total_bytes_transferred);\n}\n\nmodule_init(dma_dev_init);\nmodule_exit(dma_dev_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Kernel Academy Student\");\nMODULE_DESCRIPTION(\"Character device with DMA operations\");\nMODULE_VERSION(\"1.0\");",
  "validation": {
    "exactRequirements": {
      "functionNames": [
        "dma_dev_init",
        "dma_dev_exit",
        "allocate_coherent_memory",
        "free_coherent_memory",
        "start_dma_transfer",
        "wait_for_transfer",
        "cleanup_transfer",
        "dma_completion_timer_callback"
      ],
      "variables": [
        {"name": "dma_dev", "type": "struct dma_device"},
        {"name": "dma_dev_fops", "type": "struct file_operations"}
      ],
      "outputMessages": [
        "DMA device driver loaded successfully",
        "Device: /dev/dmadev with DMA support",
        "Coherent buffer:",
        "bytes, DMA pool:",
        "DMA device driver unloaded",
        "Final DMA stats - Started:"
      ],
      "requiredIncludes": [
        "linux/module.h",
        "linux/kernel.h",
        "linux/init.h",
        "linux/dma-mapping.h",
        "linux/dmapool.h",
        "linux/platform_device.h",
        "linux/completion.h"
      ],
      "mustContain": [
        "dma_alloc_coherent",
        "dma_free_coherent",
        "dma_pool_create",
        "dma_pool_alloc",
        "dma_pool_free",
        "dma_sync_single_for_device",
        "dma_sync_single_for_cpu",
        "dma_set_mask_and_coherent",
        "DMA_TO_DEVICE",
        "DMA_FROM_DEVICE"
      ]
    },
    "testCases": [
      {
        "id": "coherent_memory_allocation",
        "name": "Coherent Memory Allocation",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "dma_alloc_coherent(&dev->pdev->dev",
          "dma_free_coherent(&dev->pdev->dev",
          "&dev->coherent_dma_addr"
        ],
        "prohibitedSymbols": ["kmalloc", "vmalloc"]
      },
      {
        "id": "dma_pool_management",
        "name": "DMA Pool Management",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "dma_pool_create(\"demo_pool\"",
          "dma_pool_alloc(dev->dma_pool",
          "dma_pool_free(dev->dma_pool",
          "dma_pool_destroy(dma_dev.dma_pool)"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "cache_coherency",
        "name": "Cache Coherency Management",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "dma_sync_single_for_device(&dev->pdev->dev",
          "dma_sync_single_for_cpu(&dev->pdev->dev",
          "dev->stats.cache_syncs++"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "dma_direction_handling",
        "name": "DMA Direction Handling",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "enum dma_data_direction direction",
          "DMA_TO_DEVICE",
          "DMA_FROM_DEVICE",
          "if (direction == DMA_TO_DEVICE"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "platform_device_setup",
        "name": "Platform Device Setup",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "platform_device_register_simple(\"dma-demo\"",
          "dma_set_mask_and_coherent(&dma_dev.pdev->dev",
          "platform_device_unregister(dma_dev.pdev)"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "transfer_completion",
        "name": "Transfer Completion Handling",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "init_completion(&transfer->completion)",
          "complete(&transfer->completion)",
          "wait_for_completion_timeout(&transfer->completion"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "bus_address_management",
        "name": "Bus Address Management",
        "type": "code_analysis",
        "critical": true,
        "expectedSymbols": [
          "dma_addr_t dma_addr",
          "dma_addr_t pool_dma_addr",
          "transfer->dma_addr = pool_dma_addr"
        ],
        "prohibitedSymbols": []
      },
      {
        "id": "dma_support_message",
        "name": "DMA Support Message",
        "type": "output_match",
        "critical": true,
        "expected": [
          {"pattern": "Device: /dev/dmadev with DMA support", "exact": true}
        ]
      }
    ]
  }
}